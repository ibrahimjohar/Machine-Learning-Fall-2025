{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b66817",
   "metadata": {},
   "source": [
    "#### **regression**\n",
    "a statistical and machine learning technique used to model the relationship between **independent variables** (inputs/features) and a **dependent variable (output/target)**\n",
    "\n",
    "unlike classification, where outputs fall into discrete categories, regression outputs **continuous numeric values**.\n",
    "\n",
    "goal of regression is to estimate the mathematical relationship so that future, unseen values can be predicted reliably\n",
    "\n",
    "applications may include \n",
    "- Predicting house or car prices\n",
    "\n",
    "- Forecasting stock trends\n",
    "\n",
    "- Predicting electricity usage\n",
    "\n",
    "- Estimating sales or demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56f733",
   "metadata": {},
   "source": [
    "#### **linear regression**\n",
    "assumes relationship between input variables and output is **linear** - can be represented by a straight line (in 1D) or a hyperplane (in multi-dimensional space)\n",
    "\n",
    "model tries to draw a line that best fits the data by minimising the prediction error.\n",
    "\n",
    "achieved through the Least Squares Method, which finds coefficients that minimize the sum of squared differences between the predicted and actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afeb71",
   "metadata": {},
   "source": [
    "#### **simple linear regression**\n",
    "involves:\n",
    "- **one independent variable (X)**\n",
    "- **one dependent variable (Y)**\n",
    "\n",
    "$$Y=Œ≤_0‚Äã+Œ≤_1‚ÄãX$$\n",
    "\n",
    "- **Œ≤‚ÇÄ (Intercept)**: The predicted value of Y when X = 0\n",
    "\n",
    "- **Œ≤‚ÇÅ (Slope)**: How much Y changes for a unit increase in X\n",
    "\n",
    "- **X**: Independent variable\n",
    "\n",
    "- **Y**: Dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58ed32",
   "metadata": {},
   "source": [
    "#### **residuals** - error calc in regression\n",
    "a residual is the diff btw the predicted and the actual value\n",
    "$$Œµ_i‚Äã=y_‚Äã(pred)_i‚Äã‚àíy_i‚Äã$$\n",
    "\n",
    "y_(pred)_i = predicted value\n",
    "\n",
    "y_i = actual value\n",
    "\n",
    "residuals measure how far the model is from the real data.\n",
    "\n",
    "##### **Random Error**\n",
    "\n",
    "ideally, residuals should:\n",
    "\n",
    "- Look random\n",
    "\n",
    "- Have no patterns\n",
    "\n",
    "- Have constant variance\n",
    "\n",
    "_critical for valid regression._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c1f35",
   "metadata": {},
   "source": [
    "##### **measuring testing accuracies**\n",
    "testing accuracies in regression is evaluated using metrics such as:\n",
    "- **R¬≤ (Coefficient of Determination)**: How much variance the model explains\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference\n",
    "- **MSE (Mean Squared Error)**: Average squared difference\n",
    "- **RMSE**: Root of MSE (same units as target)\n",
    "\n",
    "high R¬≤ and low error values indicate a good regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327c4e3",
   "metadata": {},
   "source": [
    "#### **multiple linear regression**\n",
    "an extension of simple LR where we have **multiple independent variables**\n",
    "$$Y=Œ≤_0‚Äã+Œ≤_1‚ÄãX_1‚Äã+Œ≤_2‚ÄãX_2‚Äã+‚ãØ+Œ≤_p‚ÄãX_p‚Äã+Œµ$$\n",
    "\n",
    "- There are p features (X‚ÇÅ, X‚ÇÇ,‚Ä¶, X‚Çö)\n",
    "- The model computes one Œ≤ (coefficient) for each feature\n",
    "- Œ≤ values show the impact of each variable on the prediction\n",
    "\n",
    "like:\n",
    "\n",
    "Predicting house prices based on:\n",
    "- Area\n",
    "- Bedrooms\n",
    "- Age\n",
    "- Location\n",
    "\n",
    "each feature gets its own coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacffb87",
   "metadata": {},
   "source": [
    "#####  **considerations in multiple regression**\n",
    "1. **overfitting**\n",
    "\n",
    "    adding too many features may allow the model to memorize the training data\n",
    "\n",
    "    symptoms:\n",
    "    - very high training accuracy\n",
    "    - very low testing accuracy\n",
    "\n",
    "    solution:\n",
    "    - remove irrelevant features\n",
    "    - use regularization **(_ridge_, _lasso_)**\n",
    "    - use cross-validation\n",
    "\n",
    "2. **multi-collinearity**\n",
    "    \n",
    "    occurs when two or more independent variables strongly correlate with eachother\n",
    "\n",
    "    problems caused:\n",
    "    - coefficients become unstable\n",
    "    - interpretation becomes difficult\n",
    "    - predictions become unreliable\n",
    "\n",
    "    detection:\n",
    "    - correlation matrix\n",
    "    - VIF (variance inflation factor)\n",
    "\n",
    "3. **feature selection**\n",
    "    \n",
    "    choosing right set of features improves:\n",
    "    - accuracy\n",
    "    - interpretability\n",
    "    - speed\n",
    "\n",
    "    methods:\n",
    "    - filter methods (correlation)\n",
    "    - wrapper methods (RFE)\n",
    "    - embedded methods (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90844618",
   "metadata": {},
   "source": [
    "#### **linear regression coefficients**\n",
    "The line equation is:\n",
    "\n",
    "$$ùë¶=ùëöùë•+ùëè$$\n",
    "\n",
    "Where:\n",
    "\n",
    "-m = slope (coefficient)\n",
    "-b = intercept\n",
    "\n",
    "**interpretation:**\n",
    "\n",
    "- Coefficient (m): Indicates how much the target changes with a unit change in the predictor\n",
    "\n",
    "- Intercept (b): Target value when inputs are zero\n",
    "\n",
    "in multiple LR, each feature has its own coefficient that shows its contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75548fb",
   "metadata": {},
   "source": [
    "#### **regression plot (regplot)**\n",
    "visually represents\n",
    "- data pts (scatter plot)\n",
    "- regression line (best fit line)\n",
    "\n",
    "help judge:\n",
    "- linearity\n",
    "- presence of outliers\n",
    "- strength of relationship\n",
    "\n",
    "tighter cluster around the line -> strong relationship\n",
    "\n",
    "wide spread -> weak relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cf97a",
   "metadata": {},
   "source": [
    "#### **linear regression assumptions**\n",
    "##### **1. linearity**\n",
    "relationship between the independent and dependent variable must be linear\n",
    "\n",
    "if the pattern is curved/non-linear -> LR may be inappropriate\n",
    "\n",
    "##### **2. independence**\n",
    "observations must be independent from eachother\n",
    "\n",
    "violation example:\n",
    "- Time-series data where value at t depends on t-1\n",
    "\n",
    "##### **3. homoscendasticity (constant variance)**\n",
    "residuals must have constant variance across all predicted values\n",
    "\n",
    "if residual spread increases or decreases -> heteroscedasticity\n",
    "\n",
    "##### **4. normality of residuals**\n",
    "residual (errors) should follow a normal distribution\n",
    "\n",
    "check via:\n",
    "- histogram\n",
    "- Q-Q plot\n",
    "\n",
    "used for conducting statistical tests and confidence intervals\n",
    "\n",
    "##### **5. no perfect multicollinearity**\n",
    "independent variables should not be perfectly correlated (like X2 = 2 * X1)\n",
    "\n",
    "perfect multicollinearity prevents calculation of independent effects\n",
    "\n",
    "##### **6. no autocorrelation**\n",
    "residuals should not be correlated with eachother\n",
    "\n",
    "violation is common in time-series data\n",
    "\n",
    "##### **7. additivity**\n",
    "effects of independent variables add up linearly\n",
    "\n",
    "e.g., Effect of horsepower on price does not depend on mileage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab84a1",
   "metadata": {},
   "source": [
    "#### **polynomial linear regression**\n",
    "extends linear regression to capture non-linear patterns\n",
    "\n",
    "model becomes:\n",
    "$$y=b_0‚Äã+b_1‚Äãx+b_2‚Äãx^2+‚ãØ+b_n‚Äãx^n+Œµ$$\n",
    "\n",
    "- Degree n controls curve complexity\n",
    "\n",
    "- Higher degree = more flexibility\n",
    "\n",
    "- Too high degree = overfitting\n",
    "\n",
    "**advantages:**\n",
    "- captures non-linear patterns\n",
    "- more accurate for curved data\n",
    "\n",
    "**disadvantages:**\n",
    "- prone to overfitting\n",
    "- harder to interpret\n",
    "- sensitive to noise\n",
    "\n",
    "_Still, polynomial regression is considered ‚Äúlinear‚Äù because coefficients appear linearly in the equation_"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
