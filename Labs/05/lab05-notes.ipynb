{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d62813",
   "metadata": {},
   "source": [
    "### **what is ensemble learning**\n",
    "ensemble means combining multiple models (called base learners) to improve accuracy and robustness\n",
    "\n",
    "-> the idea is that when weak learners are going to be combined properly, they will eventually form a strong learner\n",
    "\n",
    "ensemble learning is used to:\n",
    "- reduce variance (like overfitting)\n",
    "\n",
    "- reduce bias\n",
    "\n",
    "- improve generalization\n",
    "\n",
    "##### **3 core families of ensemble methods:**\n",
    "- **bagging**\n",
    "- *type: parallel*\n",
    "- training many models independently on random subsets of data (like **RandomForest**)\n",
    "\n",
    "\n",
    "- **boosting**\n",
    "- *type: sequential*\n",
    "- training each model sequentially, where each model corrects the errors of its predecessor model (like **AdaBoost**, **XGBoost**)\n",
    "\n",
    "\n",
    "- **voting**\n",
    "- *type: simple averaging*\n",
    "- the idea is to combine predictions from multiple independent models (like using **majority voting**)\n",
    "\n",
    "\n",
    "### overview of algorithms (simple intuition)\n",
    "1. **bagging (bootstrap aggregation)**\n",
    "- randomly sample the data (with replacement)\n",
    "- train multiple models (often decision trees)\n",
    "- combine predictions using **majority voting**, e.g. **RandomForest**\n",
    "\n",
    "2. **boosting**\n",
    "- training models sequentially\n",
    "- each model learns to fix the mistakes of the previous model\n",
    "- e.g. **AdaBoost & XGBoost**\n",
    "\n",
    "3. **voting**\n",
    "- combining several trained model's predictions\n",
    "- **hard voting**: uses majority class\n",
    "- **soft voting**: averages the predicted probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1f223",
   "metadata": {},
   "source": [
    "handling null or categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f564ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #check for missing values\n",
    "\n",
    "df.dupicated().sum() #check for duplicates\n",
    "\n",
    "df = df.drop_duplicates() #remove duplicates if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613db0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if there is any object(string) columns\n",
    "\n",
    "for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    df[col] = df[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9e655",
   "metadata": {},
   "source": [
    "### **ensemble specific coding basics**\n",
    "#### **random forest (bagging)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#n_estimators is the number of trees\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5e950",
   "metadata": {},
   "source": [
    "#### **AdaBoost (boosting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "ada_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3359c",
   "metadata": {},
   "source": [
    "#### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1353b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86ffc8",
   "metadata": {},
   "source": [
    "#### **voting classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(n_estimators=[('rf', rf), ('ada', ada), ('xgb', xgb)],\n",
    "                          voting='soft')\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "vote_pred = voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c90c8",
   "metadata": {},
   "source": [
    "#### **max pooling - code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecf5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "model2.fit(x_train, y_train)\n",
    "model3.fit(x_train, y_train)\n",
    "\n",
    "#prediction\n",
    "pred1 = model1.predict(x_test)\n",
    "pred2 = model2.predict(x_test)\n",
    "pred3 = model3.predict(x_test)\n",
    "\n",
    "#final prediction\n",
    "final_pred = np.array([])\n",
    "\n",
    "for i in range(0, len(x_test)):\n",
    "    final_pred = np.append(final_pred, st.mode([pred1[i], pred2[i], pred3[i]]))\n",
    "\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77034519",
   "metadata": {},
   "source": [
    "#### **averaging - code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "model2.fit(x_train, y_train)\n",
    "model3.fit(x_train, y_train)\n",
    "\n",
    "#predict_proba -> function predicts probability score for YES and No\n",
    "pred1 = model1.predict_proba(x_test)\n",
    "pred2 = model2.predict_proba(x_test)\n",
    "pred3 = model3.predict_proba(x_test)\n",
    "\n",
    "final_pred = (pred1 + pred2 + pred3) / 3\n",
    "\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a210f8",
   "metadata": {},
   "source": [
    "#### **voting classifier using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5fefaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "estimators = [('lr', model1), ('DT', model2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bb9f4",
   "metadata": {},
   "source": [
    "#### **hard voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingClassifier(estimators=[('lr', model1), ('DT', model2)], voting='hard')\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bcf14",
   "metadata": {},
   "source": [
    "#### **soft voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01371d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingClassifier(estimators=[('lr', model1), ('DT', model2)], voting='soft')\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c466fd",
   "metadata": {},
   "source": [
    "#### **bagging meta estimator - code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = BaggingClassifier(DecisionTreeClassifier(random_state=1))\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b67ec",
   "metadata": {},
   "source": [
    "#### **adaboost - code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
